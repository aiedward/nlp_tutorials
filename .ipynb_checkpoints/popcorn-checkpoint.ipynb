{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words meets bag of popcorn\n",
    "### A tutorial in text mining and NLP\n",
    "\n",
    "Please first download the data from here:\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's first import all the libraries we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from os.path import join\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you are missing bs4 or nltk you can install them via:\n",
    "```\n",
    "pip install bs4\n",
    "pip install nltk\n",
    "python -m nltk.downloader all\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup an I/O directory and put your downloaded data there, we will call this ``root_dir`` in the following.\n",
    "#### Let's now load the data:\n",
    "##### (make sure you change the ``root_dir`` to your own path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = '/Users/arman/kaggledata/popcorn'\n",
    "\n",
    "dfTrain = pd.read_csv(join(root_dir,'labeledTrainData.tsv'),header=0,\\\n",
    "                    delimiter=\"\\t\",quoting=3)\n",
    "\n",
    "dfTest = pd.read_csv(join(root_dir,'testData.tsv'), header=0,\\\n",
    "                   delimiter=\"\\t\", quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a quick look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>\"Naturally in a film who's main themes are of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>\"This movie is a disaster within a disaster fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>\"All in all, this is a movie for kids. We saw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>\"Afraid of the Dark left me with the impressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>\"A very accurate depiction of small time mob l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             review\n",
       "0  \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
       "1    \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
       "2    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
       "3    \"7186_2\"  \"Afraid of the Dark left me with the impressio...\n",
       "4   \"12128_7\"  \"A very accurate depiction of small time mob l..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In particular note that the ``review`` column has some html tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Although I generally do not like remakes believing that remakes are waste of time; this film is an exception. I didn\\'t actually know so far until reading the previous comment that this was a remake, so my opinion is purely about the actual film and not a comparison.<br /><br />The story and the way it is written is no question: it is Capote. There is no need for more words.<br /><br />The play of Anthony Edwards and Eric Roberts is superb. I have seen some movies with them, each in one or the other. I was certain that they are good actors and in case of Eric I always wondered why his sister is the number 1 famous star and not her brother. This time this certainty is raised to fact, no question. His play, just as well as the play of Mr. Edwards is clearly the top of all their profession.<br /><br />I recommend this film to be on your top 50 films to see and keep on your DVD shelves.\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain['review'][11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our target is to use ``sentiment`` column to predict the same for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = dfTrain['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we need some sort of *\"cleaning\"* processes, we simply eliminate all the non-alphabet characters and use BeautifulSoup library to extract the text content, Let's put everything together in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False, split=False):\n",
    "    \"\"\"\n",
    "    Simple text cleaning function, \n",
    "    uses BeautifulSoup to extract text content from html\n",
    "    removes all non-alphabet\n",
    "    converts to lower case\n",
    "    can remove stopwords\n",
    "    can perform simple tokenization using split by whitespace\n",
    "    \"\"\"\n",
    "        \n",
    "    review_text = BeautifulSoup(review, 'lxml').get_text()\n",
    "    \n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    \n",
    "    if split:      \n",
    "        return(words)\n",
    "    else:\n",
    "        return(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before proceeding, let's test what our function does: on the review example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'although i generally do not like remakes believing that remakes are waste of time this film is an exception i didn t actually know so far until reading the previous comment that this was a remake so my opinion is purely about the actual film and not a comparison the story and the way it is written is no question it is capote there is no need for more words the play of anthony edwards and eric roberts is superb i have seen some movies with them each in one or the other i was certain that they are good actors and in case of eric i always wondered why his sister is the number famous star and not her brother this time this certainty is raised to fact no question his play just as well as the play of mr edwards is clearly the top of all their profession i recommend this film to be on your top films to see and keep on your dvd shelves'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_wordlist(dfTrain['review'][11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### and with the ``remove_stopwords`` flag on, it will give us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'although generally like remakes believing remakes waste time film exception actually know far reading previous comment remake opinion purely actual film comparison story way written question capote need words play anthony edwards eric roberts superb seen movies one certain good actors case eric always wondered sister number famous star brother time certainty raised fact question play well play mr edwards clearly top profession recommend film top films see keep dvd shelves'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_wordlist(dfTrain['review'][11],remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### and with ``split`` flag on, it can actually perform a simple tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['although', 'generally', 'like', 'remakes', 'believing', 'remakes', 'waste', 'time', 'film', 'exception', 'actually', 'know', 'far', 'reading', 'previous', 'comment', 'remake', 'opinion', 'purely', 'actual', 'film', 'comparison', 'story', 'way', 'written', 'question', 'capote', 'need', 'words', 'play', 'anthony', 'edwards', 'eric', 'roberts', 'superb', 'seen', 'movies', 'one', 'certain', 'good', 'actors', 'case', 'eric', 'always', 'wondered', 'sister', 'number', 'famous', 'star', 'brother', 'time', 'certainty', 'raised', 'fact', 'question', 'play', 'well', 'play', 'mr', 'edwards', 'clearly', 'top', 'profession', 'recommend', 'film', 'top', 'films', 'see', 'keep', 'dvd', 'shelves']\n"
     ]
    }
   ],
   "source": [
    "token = review_to_wordlist(dfTrain['review'][11],remove_stopwords=True, split=True)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice the words \n",
    "``reading``, ``purely``, ``written``, \n",
    "``raised``, ``films``, ``clearly`` \n",
    "#### that all need stemming, but let's for now continue with what we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now apply our cleaning process to the review columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrain['review'] =  dfTrain['review'].map(review_to_wordlist)\n",
    "dfTest['review'] =  dfTest['review'].map(review_to_wordlist)\n",
    "train_len = len(dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our corpus is all of the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = list(dfTrain['review']) + list(dfTest['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not let's use sklearn's tf-idf vectorizer with unigram and bigrams, and a log TF function (``sublinear_tf=True``)\n",
    "#### Note that we can remove the ``stop_words`` here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, ngram_range=(1, 2),\\\n",
    "                      use_idf=True,smooth_idf=True,sublinear_tf=True,\\\n",
    "                      stop_words = 'english')\n",
    "\n",
    "    \n",
    "tfv.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can now use the object ``tfv`` to build the tf-idf vector-space representation of the reviews, the transformation returns a sparse scipy matrix\n",
    "\n",
    "##### Note: Following can take upto 1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = tfv.transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice the shape of the ``X_all`` matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 302723)\n"
     ]
    }
   ],
   "source": [
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So it created about 300K numerical features! (the total count of words in the corpus + number of unique bigrams)\n",
    "#### It is highly sparse though (which allows python to use scipy's sparse matrix representation and keep everything on the RAM!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's split the ``X_all`` matrix back to our ``train`` and ``test`` set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = X_all[:train_len]\n",
    "test = X_all[train_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now use a Logistic Regression model to fit to the numerical features, (LR is quite safe here to use for such a high number of features, to use tree based models we definitely need feature selection)\n",
    "#### Let's perform a simple 5-fold cross-validation using AUC score and also fine tune one of the parameters of the LR model, the penalty constant ``c`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 1    score: 0.956977312\n",
      "c: 3    score: 0.961362912\n",
      "c: 10    score: 0.962991712\n",
      "c: 30    score: 0.963238496\n",
      "c: 100    score: 0.96315872\n",
      "c: 300    score: 0.96300336\n"
     ]
    }
   ],
   "source": [
    "Cs = [1,3,10,30,100,300]\n",
    "for c in Cs:\n",
    "    clf = LogisticRegression(penalty='l2', dual=True, tol=0.0001,\\\n",
    "                         C=c, fit_intercept=True, intercept_scaling=1.0,\\\n",
    "                         class_weight=None, random_state=None)\n",
    "                         \n",
    "    print(\"c:\",c,\"   score:\", np.mean(cross_val_score(clf, train, target,\\\n",
    "                            cv=5, scoring='roc_auc')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our CV experiment suggests that ``c = 30`` is the best choice, so we use our best model to fit to the entire train set now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=30, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1.0, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l2', dual=True, tol=0.0001,\\\n",
    "                         C=30, fit_intercept=True, intercept_scaling=1.0,\\\n",
    "                         class_weight=None, random_state=None)\n",
    "\n",
    "clf.fit(train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### and finally predicting for test set and storing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(test)[:,1]\n",
    "dfOut = pd.DataFrame( data={\"id\":dfTest[\"id\"], \"sentiment\":preds} )\n",
    "dfOut.to_csv(join(root_dir,'submission.csv'), index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you submit the output file you should get the LB score of: 0.95687 which is far better than the word2vec results 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what else can be done to improve the score:\n",
    "* Stemming\n",
    "* Better tokenization, (``\"!\"`` has sentimental value!)\n",
    "* Dimensionality reduction and building new features. For example finding a list of positive and negative sentiment words (See: [[1]](http://www.idiap.ch/~apbelis/hlt-course/positive-words.txt) [[2]](http://www.idiap.ch/~apbelis/hlt-course/negative-words.txt) ) and using the cosine similarity of those to the review \n",
    "* Feature selection (to be used for tree based models)\n",
    "  (For example see recursive feature elimination tools in sklearn: <http://scikit-learn.org/stable/modules/feature_selection.html>\n",
    "* Ensembling these results with other models (random forest, SVM, adaBoost, xgboost etc...) See Kaggle's ensembling guide: <http://mlwave.com/kaggle-ensembling-guide/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
